Introducing this project, I defined my goal as being to produce a process with which to generate a individualised HRTF set based on user-generated data, without any more equipment or expertise than the average end user of a virtual, augmented, or mixed reality system might have, on a practical time scale. The process as it currently stands does not effectively meet these requirements, though I am confident that there is merit in the proposed process - serving its function as a proof-of-concept. From a user experience standpoint, basing the individualisation process on the user's error in localisation is an approach which has the potential to be effective. There is sizable scope for gamification of the process using this method, which has the potential to encourage non-enthusiast users to undergo the process as these technologies become more widespread and their application areas become more diverse. To make it practical, however, the underlying algorithm would need to produce an individualised HRTF using a smaller amount of direct input from the user than is currently required. Using the current implementation, even if the rate of measurements were to be increased tenfold it would still take an untenably long time to produce an entire HRTF set, losing a potential point in favour of this type of method over the traditional measurement process. 

This leads into the greatest current problem with the produced implementation; it is unknown whether or not it would actually produce an effective custom HRTF set. This is part of the problem of choosing to base this project on SA, as I have discussed in previous chapters. Making pseudorandom changes to the HRTF data means that sub-optimal child states are regularly explored, and this slows the process down significantly. Given that my listening tests were limited to exploring six steps into the search process, it is difficult to estimate how many steps through the search would be required to reach a point at which the HRTF could be said to be fit the individual. Knowing, however, that it is greater than six means that it can be conluded that individualisation of a full set of HRTFs using this exact implementation is untenable for my intended application.

\section{Improvements}

It is possible that some small modifications could make this method more effective, starting with the effects on perception that result from a given adjustment value. As has been mentioned previously, the current implementation used update values taken from Josef Holzl's study. A more focused look into the effects of different ways of calculating the adjustment value could be beneficial. It would also be worth reviewing the effect that different starting HRTF sets have on the process. As has been mentioned previously, it's impossible to find HRTF data that works for everyone. But it might be possible to find a small set that work broadly as starting points for individualisation. The starting HRTF could even be selected automatically based on a similar style of localisation test. 

It has already been covered heavily in previous chapters, but a better understanding of the relationship between the PCW adjustments being made and the effect that the adjustments will have on perception could be the greatest improvement while keeping the broader implementation details largely the same. We saw in the previous chapter that there appears to be some correlation between PCW adjustment and perceived source position, and with more focused research in this area it's possible that a much clearer relationship could be identified. Coupled with a better understanding of the change produced by a given adjustment value, this could help eliminate the early missteps in the search process and allow the algorithm to make more targeted adjustments sooner, greatly lowering the total number of steps required for individualisation.

Working from the assumption that enough data can be gathered, potentially through use of or research into a greatly improved version of the current algorithm, I think there is also scope to investigate the application of more complex machine learning algorithms to this process. There are plenty of obstacles ahead of making this feasible, but assuming they could all be overcome with sufficient research time then the ideal implementation might function as follows: As with the current implementation, it should start with a neutral/default HRTF, play the user a set of sounds from a predetermined set of positions, and ask them to locate where they believe they originated from. This data should be enough (the exact amount quantified with the design of the system) to feed into a pre-trained machine learning model that should then return a more individualised HRTF. Training such a model would take more data than appears to be currently available, and the time required to generate that data could be substantial. Though if there was the potential to build the ability to capture that data into a simpler system that was actively used, it could eventually be feasible. Such a system, fantastical though it may currently be, would fulfil all of the requirements that I initially defined. Offering improved an improved spatial audio experience for a wider range of people, further increasing the accessibility of virtual reality. 
