With the recent increase in interest in technologies attempting to provide a virtual experience that convincingly replaces or seamlessly integrates with the real world, it is becoming increasingly important to be able to provide an audio experience that is equally accurate. A common way of reproducing audio for such applications is through the use of HRTFs or HRIRs, models that capture and describe the various effects that human anthropometry have on an audio signal before it arrives at the inner ear. HRTFs, however, are costly to measure, and is has become apparent that the common practice of using an average or generalised HRTF for every user is insufficient, and can cause significant confusion. This project investigates different HRTF individualisation methods, and attempts to devise and implement a method that would allow users to perform the individualisation process with no additional equipment or expertise. 