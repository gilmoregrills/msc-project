With the recent increase in interest in technologies attempting to provide a virtual experience that convincingly replaces or seamlessly integrates with the real world, it is becoming increasingly important to be able to provide an audio experience that is equally accurate. A common way of reproducing audio for such applications is through the use of Head-Related Transfer Functions (HRTFs) or Head-Related Impulse Responses (HRIRs); models that capture and describe the various effects that human anthropometry have on an audio signal before it arrives at the inner ear. HRTFs, however, are costly to measure, and is has become apparent that the common practice of using an average or generalised HRTF for every user is insufficient [toooooo long] and can cause significant localisation confusion - in which sound samples appear to come from somewhere other than the actual source. I will be investigating different HRTF individualisation methods and attempting to implement a process based on Principal Components Analysis and Simulated Annealing search; allowing users to perform the individualisation process with no additional equipment or expertise. This method is shown to produce somewhat promising results, but could be significantly improved by further investigation into the relationships between the components singled out by PCA and localisation errors. 