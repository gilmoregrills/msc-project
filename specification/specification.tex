% File: specification.tex
% Created: Tuesday 24th January
% 
% MSc Project Specification

\documentclass[10pt, oneside, a4paper, draft]{scrartcl}

\begin{document}
\bibliography{/home/gilmoregrills/Documents/library.bib}
\title{HRTF Individualisation Based on Localization Errors in 3D Space}
\subtitle{Specification}
\author{Robin Yonge}
\date{Febuary 2017}
\maketitle

\renewcommand{\abtractname}{Introduction} %maybs change to blank
\begin {abstract}
Virtual reality\ignore{Computer-mediated reality \cite{S.Mann199}} has come to represent the dominant prediction for the near future of human-computer interaction. If this prediction is to come to pass, then it is necessary that sufficient consideration is given toward the fidelity of both the visual and the auditory aspects of VR and AR technology. Currently, most implementations of spatial audio in VR and AR applications are based around the use of HRTFs. Mostof these implementations use one of a few publically available datasets, derived from measurements performed on either human subjects or a model such a the KEMAR\cite{Algazi2001}\cite{Gardner1994}. For the use of VR/AR to become commonplace the experience must be universal. Because spatial audio relies on complex measurements of real-world subjects (be they flesh and blood or not) applications tend to use average or neutral HRTFs, ones that should work for the largest number of people. Of course, by dint of being average there are many people for whom these do not work. In order to achieve a universal experience, then, it is necessary to find a process for  simple individualization of spatial audio that is sufficiently simple, and can be performed by the end user as a part of the standardsetup of any VR/AR device or application.
\end {abstract}

\section*{}


\section*{}
this is section2

\section*{}
this is section3

\end{document}


